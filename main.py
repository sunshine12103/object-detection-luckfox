import cv2
from ultralytics import YOLO
import numpy as np

class TDTULogoDetector:
    def __init__(self, model_path="runs/train/tdtu_v1_basic/weights/best.pt", data_path="LOGO-TDTU.v2i.yolov8/data.yaml"):
        print("ƒêang kh·ªüi t·∫°o YOLO model...")
        try:
            self.model = YOLO(model_path)
            print(f"ƒê√£ load model: {model_path}")
        except:
            print(f"Kh√¥ng t√¨m th·∫•y model trained, s·ª≠ d·ª•ng model g·ªëc...")
            self.model = YOLO("yolov8n.pt")
        self.data_path = data_path
        self.class_names = ['logo_tdtu']
        
        self.colors = [(0, 255, 0)]  
        
    def train_model(self, epochs=50, img_size=640):
     
        print("B·∫Øt ƒë·∫ßu training model...")
        try:
            results = self.model.train(
                data=self.data_path,
                epochs=epochs,
                imgsz=img_size,
                patience=10,
                save=True,
                device='cpu'  # C√≥ th·ªÉ ƒë·ªïi th√†nh 'cuda' n·∫øu c√≥ GPU
            )
            print("‚úÖ Training ho√†n th√†nh!")
            return results
        except Exception as e:
            print(f"‚ùå L·ªói khi training: {e}")
            return None
    
    def detect_from_webcam(self, camera_id=0, confidence_threshold=0.5):
        """
        Detect logo TDTU t·ª´ webcam real-time
        """
        print("üìπ ƒêang m·ªü webcam...")
        cap = cv2.VideoCapture(camera_id)
        
        if not cap.isOpened():
            print("‚ùå Kh√¥ng th·ªÉ m·ªü webcam!")
            return
        
        print("‚úÖ Webcam ƒë√£ s·∫µn s√†ng!")
        print("üìù Nh·∫•n 'q' ƒë·ªÉ tho√°t, 'r' ƒë·ªÉ reset, 's' ƒë·ªÉ ch·ª•p ·∫£nh")
        
        frame_count = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ webcam!")
                break
            
            frame_count += 1
            
            # Detect objects trong frame
            results = self.model(frame, conf=confidence_threshold, verbose=False)
            
            # V·∫Ω k·∫øt qu·∫£ l√™n frame
            annotated_frame = self.draw_results(frame, results)
            
            # Hi·ªÉn th·ªã FPS
            fps_text = f"Frame: {frame_count}"
            cv2.putText(annotated_frame, fps_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # Hi·ªÉn th·ªã frame
            cv2.imshow('TDTU Logo Detection', annotated_frame)
            
            # X·ª≠ l√Ω ph√≠m b·∫•m
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('r'):
                frame_count = 0
                print("üîÑ Reset frame counter")
            elif key == ord('s'):
                filename = f'screenshot_{frame_count}.jpg'
                cv2.imwrite(filename, annotated_frame)
                print(f"üì∏ ƒê√£ l∆∞u ·∫£nh: {filename}")
        
        cap.release()
        cv2.destroyAllWindows()
        print("üëã ƒê√£ ƒë√≥ng webcam!")
    
    def draw_results(self, frame, results):
        """
        V·∫Ω bounding box v√† label l√™n frame
        """
        annotated_frame = frame.copy()
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # L·∫•y t·ªça ƒë·ªô bounding box
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                    confidence = box.conf[0].cpu().numpy()
                    class_id = int(box.cls[0].cpu().numpy())
                    
                    # Ch·ªâ hi·ªÉn th·ªã n·∫øu confidence ƒë·ªß cao
                    if confidence > 0.3:
                        # V·∫Ω bounding box
                        color = self.colors[0]  # M√†u xanh l√° cho logo TDTU
                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                        
                        # T·∫°o label
                        label = f'LOGO TDTU: {confidence:.2f}'
                        
                        # V·∫Ω background cho text
                        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
                        cv2.rectangle(annotated_frame, (x1, y1 - 20), (x1 + w, y1), color, -1)
                        
                        # V·∫Ω text
                        cv2.putText(annotated_frame, label, (x1, y1 - 5),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
                        
                        print(f"üéØ Ph√°t hi·ªán logo TDTU! Confidence: {confidence:.2f}")
        
        return annotated_frame
    
    def test_on_images(self, image_folder="LOGO-TDTU.v2i.yolov8/test/images"):
        """
        Test model tr√™n c√°c ·∫£nh trong th∆∞ m·ª•c test
        """
        import os
        print(f"üß™ Testing model tr√™n ·∫£nh trong th∆∞ m·ª•c: {image_folder}")
        
        if not os.path.exists(image_folder):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {image_folder}")
            return
        
        image_files = [f for f in os.listdir(image_folder) 
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not image_files:
            print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong th∆∞ m·ª•c!")
            return
        
        for img_file in image_files[:5]:  # Test 5 ·∫£nh ƒë·∫ßu
            img_path = os.path.join(image_folder, img_file)
            print(f"üìÑ Testing: {img_file}")
            
            # Load v√† predict
            results = self.model(img_path, conf=0.5)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            for result in results:
                result.show()
                
        print("‚úÖ Test ho√†n th√†nh!")

def main():
    """
    H√†m main ƒë·ªÉ ch·∫°y detector
    """
    print("üéì TDTU Logo Detector - YOLOv8")
    print("=" * 40)
    
    detector = TDTULogoDetector()
    
    while True:
        print("\nCh·ªçn ch·ª©c nƒÉng:")
        print("1. Train model v·ªõi dataset TDTU")
        print("2. Detect logo t·ª´ webcam")
        print("3. Test model tr√™n ·∫£nh m·∫´u")
        print("4. Tho√°t")
        
        choice = input("Nh·∫≠p l·ª±a ch·ªçn (1-4): ").strip()
        
        if choice == "1":
            epochs = input("S·ªë epochs (m·∫∑c ƒë·ªãnh 50): ").strip()
            epochs = int(epochs) if epochs.isdigit() else 50
            detector.train_model(epochs=epochs)
            
        elif choice == "2":
            camera_id = input("Camera ID (m·∫∑c ƒë·ªãnh 0): ").strip()
            camera_id = int(camera_id) if camera_id.isdigit() else 0
            
            confidence = input("Confidence threshold (m·∫∑c ƒë·ªãnh 0.5): ").strip()
            confidence = float(confidence) if confidence else 0.5
            
            detector.detect_from_webcam(camera_id=camera_id, 
                                      confidence_threshold=confidence)
            
        elif choice == "3":
            detector.test_on_images()
            
        elif choice == "4":
            print("üëã T·∫°m bi·ªát!")
            break
            
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")

if __name__ == "__main__":
    main()